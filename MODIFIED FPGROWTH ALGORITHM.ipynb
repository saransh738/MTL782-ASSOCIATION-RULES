{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009f001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets are:\n",
      " {'10515'} with frequency  882\n",
      " {'264'} with frequency  895\n",
      " {'2958'} with frequency  904\n",
      " {'45'} with frequency  911\n",
      " {'242'} with frequency  911\n",
      " {'956'} with frequency  911\n",
      " {'31'} with frequency  920\n",
      " {'479'} with frequency  926\n",
      " {'3270'} with frequency  950\n",
      " {'783'} with frequency  965\n",
      " {'175'} with frequency  970\n",
      " {'522'} with frequency  974\n",
      " {'258'} with frequency  987\n",
      " {'179'} with frequency  998\n",
      " {'19'} with frequency  1005\n",
      " {'161'} with frequency  1010\n",
      " {'117'} with frequency  1026\n",
      " {'13041'} with frequency  1051\n",
      " {'78'} with frequency  1060\n",
      " {'37'} with frequency  1074\n",
      " {'38', '37'} with frequency  1046\n",
      " {'1004'} with frequency  1102\n",
      " {'677'} with frequency  1110\n",
      " {'589'} with frequency  1119\n",
      " {'49'} with frequency  1120\n",
      " {'201'} with frequency  1133\n",
      " {'548'} with frequency  1137\n",
      " {'15832'} with frequency  1143\n",
      " {'249'} with frequency  1160\n",
      " {'1393'} with frequency  1161\n",
      " {'16217'} with frequency  1166\n",
      " {'740'} with frequency  1181\n",
      " {'286'} with frequency  1183\n",
      " {'38', '286'} with frequency  1116\n",
      " {'301'} with frequency  1204\n",
      " {'604'} with frequency  1209\n",
      " {'824'} with frequency  1210\n",
      " {'592'} with frequency  1227\n",
      " {'338'} with frequency  1274\n",
      " {'14098'} with frequency  1291\n",
      " {'123'} with frequency  1302\n",
      " {'16010'} with frequency  1316\n",
      " {'9'} with frequency  1372\n",
      " {'185'} with frequency  1376\n",
      " {'1146'} with frequency  1426\n",
      " {'39', '1146'} with frequency  983\n",
      " {'12925'} with frequency  1467\n",
      " {'39', '12925'} with frequency  938\n",
      " {'255'} with frequency  1474\n",
      " {'48', '255'} with frequency  1057\n",
      " {'39', '255'} with frequency  1057\n",
      " {'533'} with frequency  1487\n",
      " {'533', '39'} with frequency  922\n",
      " {'60'} with frequency  1489\n",
      " {'39', '60'} with frequency  983\n",
      " {'79'} with frequency  1600\n",
      " {'79', '48'} with frequency  893\n",
      " {'39', '79'} with frequency  1111\n",
      " {'2238'} with frequency  1715\n",
      " {'48', '2238'} with frequency  955\n",
      " {'39', '2238'} with frequency  1287\n",
      " {'270'} with frequency  1734\n",
      " {'270', '48'} with frequency  957\n",
      " {'270', '39'} with frequency  1194\n",
      " {'147'} with frequency  1779\n",
      " {'147', '48'} with frequency  1036\n",
      " {'147', '39'} with frequency  1137\n",
      " {'1327'} with frequency  1786\n",
      " {'1327', '48'} with frequency  968\n",
      " {'39', '1327'} with frequency  1156\n",
      " {'438'} with frequency  1863\n",
      " {'438', '48'} with frequency  1025\n",
      " {'438', '39'} with frequency  1260\n",
      " {'413'} with frequency  1880\n",
      " {'39', '413'} with frequency  1130\n",
      " {'48', '413'} with frequency  1135\n",
      " {'271'} with frequency  2094\n",
      " {'271', '48'} with frequency  1090\n",
      " {'271', '39'} with frequency  1434\n",
      " {'475'} with frequency  2167\n",
      " {'475', '48'} with frequency  1428\n",
      " {'475', '39', '48'} with frequency  1092\n",
      " {'475', '39'} with frequency  1500\n",
      " {'101'} with frequency  2237\n",
      " {'101', '48'} with frequency  1311\n",
      " {'39', '101', '48'} with frequency  946\n",
      " {'39', '101'} with frequency  1400\n",
      " {'310'} with frequency  2594\n",
      " {'310', '48'} with frequency  1692\n",
      " {'39', '310', '48'} with frequency  1347\n",
      " {'39', '310'} with frequency  1852\n",
      " {'110'} with frequency  2794\n",
      " {'110', '48'} with frequency  1380\n",
      " {'39', '110', '48'} with frequency  1037\n",
      " {'38', '39', '110', '48'} with frequency  1031\n",
      " {'38', '110', '48'} with frequency  1361\n",
      " {'39', '110'} with frequency  1759\n",
      " {'38', '39', '110'} with frequency  1740\n",
      " {'38', '110'} with frequency  2725\n",
      " {'36'} with frequency  2936\n",
      " {'48', '36'} with frequency  1416\n",
      " {'39', '48', '36'} with frequency  1116\n",
      " {'38', '39', '48', '36'} with frequency  1080\n",
      " {'38', '48', '36'} with frequency  1360\n",
      " {'39', '36'} with frequency  2037\n",
      " {'38', '39', '36'} with frequency  1945\n",
      " {'38', '36'} with frequency  2790\n",
      " {'237'} with frequency  3032\n",
      " {'237', '48'} with frequency  1682\n",
      " {'39', '237', '48'} with frequency  1244\n",
      " {'39', '237'} with frequency  1929\n",
      " {'170'} with frequency  3099\n",
      " {'170', '48'} with frequency  1557\n",
      " {'170', '39', '48'} with frequency  1206\n",
      " {'170', '39', '48', '38'} with frequency  1193\n",
      " {'170', '48', '38'} with frequency  1538\n",
      " {'170', '39'} with frequency  2059\n",
      " {'170', '39', '38'} with frequency  2019\n",
      " {'170', '38'} with frequency  3031\n",
      " {'225'} with frequency  3257\n",
      " {'225', '48'} with frequency  1736\n",
      " {'39', '225', '48'} with frequency  1400\n",
      " {'39', '225'} with frequency  2351\n",
      " {'89'} with frequency  3837\n",
      " {'89', '39'} with frequency  2749\n",
      " {'89', '48', '39'} with frequency  2125\n",
      " {'89', '48'} with frequency  2798\n",
      " {'65'} with frequency  4472\n",
      " {'65', '41'} with frequency  995\n",
      " {'65', '48'} with frequency  2529\n",
      " {'39', '65', '48'} with frequency  1797\n",
      " {'39', '65'} with frequency  2787\n",
      " {'41'} with frequency  14945\n",
      " {'32', '41'} with frequency  3196\n",
      " {'32', '48', '41'} with frequency  2063\n",
      " {'32', '39', '48', '41'} with frequency  1646\n",
      " {'32', '39', '41'} with frequency  2359\n",
      " {'38', '41'} with frequency  3897\n",
      " {'38', '48', '41'} with frequency  2374\n",
      " {'38', '39', '48', '41'} with frequency  1991\n",
      " {'38', '39', '41'} with frequency  3051\n",
      " {'48', '41'} with frequency  9018\n",
      " {'39', '48', '41'} with frequency  7366\n",
      " {'39', '41'} with frequency  11414\n",
      " {'32'} with frequency  15167\n",
      " {'38', '32'} with frequency  2833\n",
      " {'38', '32', '48'} with frequency  1646\n",
      " {'38', '32', '39', '48'} with frequency  1236\n",
      " {'38', '32', '39'} with frequency  1840\n",
      " {'32', '48'} with frequency  8034\n",
      " {'32', '39', '48'} with frequency  5402\n",
      " {'32', '39'} with frequency  8455\n",
      " {'38'} with frequency  15596\n",
      " {'38', '48'} with frequency  7944\n",
      " {'38', '39', '48'} with frequency  6102\n",
      " {'38', '39'} with frequency  10345\n",
      " {'48'} with frequency  42135\n",
      " {'39', '48'} with frequency  29142\n",
      " {'39'} with frequency  50675\n",
      "\n",
      " Total frequent items are 159 \n",
      "\n",
      "Association rules are:\n",
      "{'37'} => {'38'} at confidence 0.9739292364990689\n",
      "{'286'} => {'38'} at confidence 0.9433643279797126\n",
      "{'39', '110', '48'} => {'38'} at confidence 0.9942140790742526\n",
      "{'110', '48'} => {'38'} at confidence 0.986231884057971\n",
      "{'39', '110'} => {'38'} at confidence 0.9891984081864695\n",
      "{'110'} => {'38'} at confidence 0.9753042233357194\n",
      "{'39', '48', '36'} => {'38'} at confidence 0.967741935483871\n",
      "{'48', '36'} => {'38'} at confidence 0.96045197740113\n",
      "{'39', '36'} => {'38'} at confidence 0.9548355424644085\n",
      "{'36'} => {'38'} at confidence 0.9502724795640327\n",
      "{'170', '39', '48'} => {'38'} at confidence 0.9892205638474295\n",
      "{'170', '48'} => {'38'} at confidence 0.9877970456005138\n",
      "{'170', '39'} => {'38'} at confidence 0.9805730937348227\n",
      "{'170'} => {'38'} at confidence 0.9780574378831881\n",
      "{'225', '48'} => {'39'} at confidence 0.8064516129032258\n",
      "{'38', '48', '41'} => {'39'} at confidence 0.8386689132266217\n",
      "{'48', '41'} => {'39'} at confidence 0.8168108227988468\n",
      "\n",
      " Total Time taken is 7.8900182247161865 seconds\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "import time \n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class FPNode:\n",
    "    def __init__(self,ID,ancestor,frequency):\n",
    "        self.ID = ID   #id of the fpnode class item\n",
    "        self.descendent = {} #child of the fpnode class item\n",
    "        self.frequency = frequency #frequency of the fpnode class item\n",
    "        self.Ancestor = ancestor #parent of the fpnode class item\n",
    "        self.N_Link = None #link node of the fpnode class\n",
    "        \n",
    "def projected_Construct_FP(S_min,DataBase):\n",
    "    Reference_Table = {}   \n",
    "    for row in DataBase:\n",
    "        for element in row:\n",
    "            # if item is not in reference table, we will add it from database\n",
    "            if(Reference_Table.get(element)==None): \n",
    "                Reference_Table[element]=DataBase[row]\n",
    "            # if item is in reference table, we will update it using database\n",
    "            else:\n",
    "                Reference_Table[element] = Reference_Table.get(element) + DataBase[row]\n",
    "    #now,we will delete elements having support less than minimum support\n",
    "    for element in list(Reference_Table):\n",
    "        if Reference_Table[element] < S_min: del(Reference_Table[element])\n",
    "   # now we form frequent 1 itemset i.e. recurrent_set         \n",
    "    recurrent_set = set(Reference_Table.keys())\n",
    "    # if no recurrent set , return none\n",
    "    n=len(recurrent_set)\n",
    "    if n == 0: return None, None\n",
    "    \n",
    "    # now create reference table in the form of [element,{frequency,nodelink}]\n",
    "    for element in Reference_Table:\n",
    "        Reference_Table[element] = [Reference_Table[element], None]\n",
    "\n",
    " \n",
    "   #############################################################333###################################    \n",
    "    # now we will break database into projected database\n",
    "    DBS=[]\n",
    "    RTable=sorted(Reference_Table.items(),key=lambda p: p[1][0],reverse=True)\n",
    "    for i in range(len(RTable)):\n",
    "        element1 =RTable[i][0]\n",
    "        PDB={}\n",
    "        y=DataBase.copy()\n",
    "        y.clear()\n",
    "        y=DataBase.copy()\n",
    "        for Set,freq in y.items():\n",
    "            if element1 in Set:\n",
    "                PDB[Set]=freq\n",
    "                del(DataBase[Set])\n",
    "        DBS.append(PDB)\n",
    "    \n",
    "        \n",
    "\n",
    "    FTREES=[]\n",
    "    RT=[]\n",
    "    for i in range(len(DBS)):\n",
    "        database=DBS[i]\n",
    "        R_Table=Reference_Table\n",
    "        # initialize fptree using null set\n",
    "        FPTREE = FPNode('Null Set',None,1)\n",
    "        #now,we will again scan the data second time and make the fptree\n",
    "        for SET,freq in database.items():\n",
    "            recurrent_items = {}\n",
    "            for element in SET:\n",
    "                if element in recurrent_set: recurrent_items[element] = R_Table[element][0]\n",
    "            if len(recurrent_items) != 0:\n",
    "                #now we will order the elements in the decreasing order of frequency count\n",
    "                ordered_SET = [v[0] for v in sorted(recurrent_items.items(), key=lambda p: p[1], reverse=True)]\n",
    "                # now we will update the fpTree\n",
    "                SET,tree=ordered_SET,FPTREE\n",
    "                n,i=len(SET),0\n",
    "                while(i<n):\n",
    "                    # if element is not in tree.descendent, we will make a new node for it\n",
    "                    if SET[i] not in tree.descendent:\n",
    "                        tree.descendent[SET[i]] = FPNode(SET[i],tree,freq)\n",
    "                        if R_Table[SET[i]][1] == None: R_Table[SET[i]][1] = tree.descendent[SET[i]]\n",
    "                        else:\n",
    "                            Test_Node=R_Table[SET[i]][1]\n",
    "                            # we will update the link node here\n",
    "                            while (Test_Node.N_Link != None):\n",
    "                                Test_Node = Test_Node.N_Link\n",
    "                            Test_Node.N_Link = tree.descendent[SET[i]]       \n",
    "                    else:\n",
    "                         tree.descendent[SET[i]].frequency +=freq\n",
    "                    if i!= n-1: tree=tree.descendent[SET[i]]\n",
    "                    i =i+1 \n",
    "        FTREES.append(FPTREE)\n",
    "        RT.append(R_Table)\n",
    "  #############################################################################################################                  \n",
    "    return FTREES, RT\n",
    "\n",
    "def assoRule(Set,frequency_set,minimum_confidence):\n",
    "    for i in range(len(Set)):\n",
    "        subsets = chain.from_iterable(combinations(Set[i],r) for r in range(1,len(Set[i])))\n",
    "        itemSetSup = frequency_set[i]\n",
    "        for s in subsets:\n",
    "            conf = float(itemSetSup / frequency_set[Set.index(set(s))])\n",
    "            if(conf > minimum_confidence):\n",
    "                print(\"{} => {} at confidence {}\".format(set(s), set(Set[i].difference(s)), conf))\n",
    "    \n",
    "def FP_Mine(tree, Reference_Table, S_min, pathprefix, recurrent_set,frequency_set):\n",
    "    # now we will mine the given fptree\n",
    "    y=sorted(Reference_Table.items(),key=lambda p: p[1][0])\n",
    "     # list contain items and their frequency from the reference table\n",
    "    List = [[x[0],x[1][0]] for x in y]\n",
    "    for L in List:\n",
    "        new_recurrentset = pathprefix.copy() # we will copy old prefix path\n",
    "        new_recurrentset.add(L[0]) # add element in set\n",
    "        if (new_recurrentset not in recurrent_set):\n",
    "            frequency_set.append(L[1]) # add corrosponding frquency in the set\n",
    "            recurrent_set.append(new_recurrentset)  \n",
    "        #define new fpnode\n",
    "        FPNode=Reference_Table[L[0]][1]\n",
    "        cp_base = {}  # conditional_patterns_base\n",
    "        #we will find prefixpath for the given element\n",
    "        while FPNode != None:\n",
    "            path_prefix = []\n",
    "            LNode=FPNode\n",
    "            while(LNode.Ancestor !=None):\n",
    "                path_prefix.append(LNode.ID)\n",
    "                LNode=LNode.Ancestor\n",
    "            if len(path_prefix) != 1: cp_base[tuple(path_prefix[1:])] = FPNode.frequency\n",
    "            FPNode = FPNode.N_Link\n",
    "            # we will remove element from fptree which have support less than support minimum\n",
    "        c_tree, c_header = projected_Construct_FP(S_min,cp_base)\n",
    "        if c_header != None: FP_Mine(c_tree, c_header[0], S_min, new_recurrentset, recurrent_set,frequency_set)\n",
    "\n",
    "def main(input_file,S_min):\n",
    "    # now we will open our file\n",
    "    with open(input_file) as file:\n",
    "        DataBase = file.readlines()\n",
    "    elements = [row.strip() for row in DataBase]\n",
    "    Tns = []\n",
    "    n=len(elements)\n",
    "    \n",
    "    for i in range(n): Tns.append(elements[i].split())\n",
    "    Dataset = defaultdict(int)\n",
    "    for row in Tns: Dataset[tuple(row)] += 1\n",
    "    recurrent_set,frequency_set = [],[]     \n",
    "    trees, Reference_Table = projected_Construct_FP(S_min,Dataset) #tree making\n",
    "    for i in range(len(trees)):\n",
    "        FP_Mine(trees[i], Reference_Table[i], S_min, set([]), recurrent_set,frequency_set)  #mining\n",
    "    print(\"Frequent itemsets are:\")\n",
    "    for i in range(len(frequency_set)):\n",
    "        print(\" {} with frequency  {}\".format(recurrent_set[i],frequency_set[i]))\n",
    "    print(\"\\n Total frequent items are {} \\n\".format(len(recurrent_set)))\n",
    "    print(\"Association rules are:\")\n",
    "    assoRule(recurrent_set,frequency_set,0.8)\n",
    "\n",
    "\n",
    "start= time.time()\n",
    "main(\"data.txt\",881)\n",
    "end=time.time()\n",
    "print(\"\\n Total Time taken is {} seconds\".format( end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293cd12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
